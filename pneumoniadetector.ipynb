{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-16T17:24:46.892438Z","iopub.status.busy":"2024-09-16T17:24:46.892051Z","iopub.status.idle":"2024-09-16T17:25:00.838781Z","shell.execute_reply":"2024-09-16T17:25:00.837632Z","shell.execute_reply.started":"2024-09-16T17:24:46.892392Z"},"trusted":true},"outputs":[],"source":["!pip install tensorflow"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T17:25:00.841641Z","iopub.status.busy":"2024-09-16T17:25:00.841202Z","iopub.status.idle":"2024-09-16T17:25:13.247873Z","shell.execute_reply":"2024-09-16T17:25:13.246838Z","shell.execute_reply.started":"2024-09-16T17:25:00.841593Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.applications import MobileNetV2"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T17:25:13.249622Z","iopub.status.busy":"2024-09-16T17:25:13.249076Z","iopub.status.idle":"2024-09-16T17:25:13.285026Z","shell.execute_reply":"2024-09-16T17:25:13.284299Z","shell.execute_reply.started":"2024-09-16T17:25:13.249587Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Activation, Flatten\n","from tensorflow.keras.layers import Conv2D, MaxPool2D, ZeroPadding2D\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.models import Model, Sequential\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T17:25:13.288112Z","iopub.status.busy":"2024-09-16T17:25:13.287245Z","iopub.status.idle":"2024-09-16T17:25:15.174108Z","shell.execute_reply":"2024-09-16T17:25:15.173319Z","shell.execute_reply.started":"2024-09-16T17:25:13.288078Z"},"trusted":true},"outputs":[],"source":["img_width,img_height=224,224\n","\n","model=MobileNetV2(weights='imagenet',\n","                include_top=False,\n","                input_shape=(img_height,img_width,3)\n","                )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T17:25:15.175749Z","iopub.status.busy":"2024-09-16T17:25:15.175456Z","iopub.status.idle":"2024-09-16T17:25:15.182722Z","shell.execute_reply":"2024-09-16T17:25:15.181780Z","shell.execute_reply.started":"2024-09-16T17:25:15.175718Z"},"trusted":true},"outputs":[],"source":["for (i,layer) in enumerate(model.layers):\n","    print(f\"{i} {layer.__class__.__name__} {layer.trainable}\")"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T17:25:15.184432Z","iopub.status.busy":"2024-09-16T17:25:15.184052Z","iopub.status.idle":"2024-09-16T17:25:15.197153Z","shell.execute_reply":"2024-09-16T17:25:15.196311Z","shell.execute_reply.started":"2024-09-16T17:25:15.184391Z"},"trusted":true},"outputs":[],"source":["for layer in model.layers:\n","    layer.trainable=False"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T17:25:15.198465Z","iopub.status.busy":"2024-09-16T17:25:15.198154Z","iopub.status.idle":"2024-09-16T17:25:15.209955Z","shell.execute_reply":"2024-09-16T17:25:15.209086Z","shell.execute_reply.started":"2024-09-16T17:25:15.198434Z"},"trusted":true},"outputs":[],"source":["for (i,layer) in enumerate(model.layers):\n","    print(f\"{i} {layer.__class__.__name__} {layer.trainable}\")"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T17:25:15.211185Z","iopub.status.busy":"2024-09-16T17:25:15.210923Z","iopub.status.idle":"2024-09-16T17:25:15.220939Z","shell.execute_reply":"2024-09-16T17:25:15.220128Z","shell.execute_reply.started":"2024-09-16T17:25:15.211156Z"},"trusted":true},"outputs":[],"source":["def add_layer_at_bottom(bottom_model, num_classes):\n","    top_model = bottom_model.output\n","    top_model = GlobalAveragePooling2D()(top_model)\n","    top_model = Dense(1024,activation='relu')(top_model)\n","    top_model = Dense(1024,activation='relu')(top_model)\n","    top_model = Dense(512,activation='relu')(top_model)\n","    top_model = Dense(num_classes,activation='softmax')(top_model)\n","    return top_model"]},{"cell_type":"markdown","metadata":{},"source":["# Data Preprocessing"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T17:25:15.222434Z","iopub.status.busy":"2024-09-16T17:25:15.222102Z","iopub.status.idle":"2024-09-16T17:25:15.231743Z","shell.execute_reply":"2024-09-16T17:25:15.230834Z","shell.execute_reply.started":"2024-09-16T17:25:15.222384Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T17:25:15.235629Z","iopub.status.busy":"2024-09-16T17:25:15.235334Z","iopub.status.idle":"2024-09-16T17:25:15.244709Z","shell.execute_reply":"2024-09-16T17:25:15.243862Z","shell.execute_reply.started":"2024-09-16T17:25:15.235600Z"},"trusted":true},"outputs":[],"source":["train_data_dir='/kaggle/input/chest-xray-pneumonia/chest_xray/train'\n","val_data_dir='/kaggle/input/chest-xray-pneumonia/chest_xray/test'"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T17:25:15.246095Z","iopub.status.busy":"2024-09-16T17:25:15.245788Z","iopub.status.idle":"2024-09-16T17:25:15.254872Z","shell.execute_reply":"2024-09-16T17:25:15.253995Z","shell.execute_reply.started":"2024-09-16T17:25:15.246065Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","train_datagen=ImageDataGenerator(rescale=1./255,\n","                                 rotation_range=45,\n","                                 width_shift_range=0.3,\n","                                 height_shift_range=0.3,\n","                                 horizontal_flip=True,\n","                                 fill_mode='nearest')\n","\n","val_datagen=ImageDataGenerator(rescale=1./255)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T17:25:15.256101Z","iopub.status.busy":"2024-09-16T17:25:15.255811Z","iopub.status.idle":"2024-09-16T17:25:15.264961Z","shell.execute_reply":"2024-09-16T17:25:15.264068Z","shell.execute_reply.started":"2024-09-16T17:25:15.256058Z"},"trusted":true},"outputs":[],"source":["batch_size=32"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T17:25:15.266327Z","iopub.status.busy":"2024-09-16T17:25:15.265998Z","iopub.status.idle":"2024-09-16T17:25:17.097121Z","shell.execute_reply":"2024-09-16T17:25:17.096314Z","shell.execute_reply.started":"2024-09-16T17:25:15.266287Z"},"trusted":true},"outputs":[],"source":["train_generator=train_datagen.flow_from_directory(train_data_dir,\n","                                                  target_size=(img_height,img_width),\n","                                                  batch_size=batch_size,\n","                                                  class_mode='categorical')\n","\n","val_generator=val_datagen.flow_from_directory(val_data_dir,\n","                                              target_size=(img_height,img_width),\n","                                              batch_size=batch_size,\n","                                              class_mode='categorical')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T17:25:17.098457Z","iopub.status.busy":"2024-09-16T17:25:17.098144Z","iopub.status.idle":"2024-09-16T17:25:17.110599Z","shell.execute_reply":"2024-09-16T17:25:17.109743Z","shell.execute_reply.started":"2024-09-16T17:25:17.098425Z"},"trusted":true},"outputs":[],"source":["train_class_names = set()\n","num_train_samples=0\n","for i in train_generator.filenames:\n","    train_class_names.add(i.split('/')[0])\n","    num_train_samples+=1\n","print(num_train_samples)\n","train_class_names"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["val_class_names = set()\n","num_val_samples=0\n","for i in val_generator.filenames:\n","    val_class_names.add(i.split('/')[0])\n","    num_val_samples+=1\n","print(num_val_samples)\n","val_class_names"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T17:25:17.149212Z","iopub.status.busy":"2024-09-16T17:25:17.148550Z","iopub.status.idle":"2024-09-16T17:25:17.443028Z","shell.execute_reply":"2024-09-16T17:25:17.442019Z","shell.execute_reply.started":"2024-09-16T17:25:17.149177Z"},"trusted":true},"outputs":[],"source":["num_classes=len(train_generator.class_indices)\n","print(num_classes)\n","FC_head=add_layer_at_bottom(model,\n","                            num_classes)\n","\n","main_model=Model(inputs=model.input,\n","                 outputs=FC_head)\n","\n","main_model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T17:25:17.445071Z","iopub.status.busy":"2024-09-16T17:25:17.444535Z","iopub.status.idle":"2024-09-16T17:25:17.454663Z","shell.execute_reply":"2024-09-16T17:25:17.453669Z","shell.execute_reply.started":"2024-09-16T17:25:17.445026Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T17:38:57.696490Z","iopub.status.busy":"2024-09-16T17:38:57.695794Z","iopub.status.idle":"2024-09-16T17:48:36.442277Z","shell.execute_reply":"2024-09-16T17:48:36.441311Z","shell.execute_reply.started":"2024-09-16T17:38:57.696448Z"},"trusted":true},"outputs":[],"source":["# Training code\n","checkpoint = ModelCheckpoint(\"Facial_recogNet.keras\",\n","                             monitor='val_loss',\n","                             mode='min',\n","                             save_best_only=True,\n","                             verbose=1)\n","\n","earlystop = EarlyStopping(monitor='val_loss',\n","                          min_delta=0,\n","                          patience=8,\n","                          verbose=1,\n","                          restore_best_weights=True)\n","\n","callbacks = [checkpoint, earlystop]\n","\n","main_model.compile(loss='categorical_crossentropy',\n","                   optimizer=RMSprop(learning_rate=0.0015),\n","                   metrics=['accuracy'])\n","\n","epochs = 10\n","batch_size = 32\n","\n","history = main_model.fit(train_generator,\n","                         steps_per_epoch=num_train_samples // batch_size,\n","                         epochs=epochs,\n","                         callbacks=callbacks,\n","                         validation_data=val_generator,\n","                         validation_steps=num_val_samples // batch_size)\n","\n","# Save the final model\n","main_model.save('final_Facial_recogNet.keras')\n","\n","# Plot accuracy and loss\n","import matplotlib.pyplot as plt\n","\n","# Plot training & validation accuracy values\n","plt.figure(figsize=(12, 6))\n","plt.subplot(1, 2, 1)\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('Model Accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Validation'], loc='upper left')\n","\n","# Plot training & validation loss values\n","plt.subplot(1, 2, 2)\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model Loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Validation'], loc='upper left')\n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-16T17:51:05.367239Z","iopub.status.busy":"2024-09-16T17:51:05.366787Z","iopub.status.idle":"2024-09-16T17:51:05.712484Z","shell.execute_reply":"2024-09-16T17:51:05.711586Z","shell.execute_reply.started":"2024-09-16T17:51:05.367200Z"},"trusted":true},"outputs":[],"source":["import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","out = ['NORMAL', 'PNEUMONIA']\n","img = cv2.imread(\"/kaggle/input/chest-xray-pneumonia/chest_xray/test/PNEUMONIA/person101_bacteria_486.jpeg\")\n","img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","img = cv2.resize(img, (224, 224))\n","img = img / 255.\n","\n","plt.imshow(img)\n","plt.show()\n","\n","img = img.reshape(1, 224, 224, 3)\n","\n","res = main_model.predict(img)\n","print(res)\n","print(\"Predicted class:\", out[np.argmax(res)])\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":17810,"sourceId":23812,"sourceType":"datasetVersion"},{"isSourceIdPinned":true,"modelId":120671,"modelInstanceId":96494,"sourceId":114895,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30761,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
